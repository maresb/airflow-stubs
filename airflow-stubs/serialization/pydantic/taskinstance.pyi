import airflow.utils.log.logging_mixin
import airflow.utils.pydantic
import pendulum
from airflow.models.baseoperator import BaseOperator as BaseOperator
from airflow.models.taskinstance import TaskInstance as TaskInstance
from airflow.serialization.pydantic.dag import DagModelPydantic as DagModelPydantic
from airflow.serialization.pydantic.dag_run import DagRunPydantic as DagRunPydantic
from airflow.utils.log.logging_mixin import LoggingMixin as LoggingMixin
from airflow.utils.net import get_hostname as get_hostname
from airflow.utils.pydantic import BaseModelPydantic as BaseModelPydantic, ConfigDict as ConfigDict, PlainSerializer as PlainSerializer, PlainValidator as PlainValidator, is_pydantic_2_installed as is_pydantic_2_installed
from airflow.utils.session import provide_session as provide_session
from typing import Any, ClassVar, Iterable, Operator

TYPE_CHECKING: bool
NEW_SESSION: None
XCOM_RETURN_KEY: str
def serialize_operator(x: Operator) -> dict: ...
def validated_operator(x: dict[str, Any] | Operator, _info: ValidationInfo) -> Any: ...

class TaskInstancePydantic(airflow.utils.pydantic.BaseModel, airflow.utils.log.logging_mixin.LoggingMixin):
    model_config: ClassVar[airflow.utils.pydantic.ConfigDict] = ...
    def init_run_context(self, raw: bool = ...) -> None: ...
    def xcom_pull(self, task_ids: str | Iterable[str] | None = ..., dag_id: str | None = ..., key: str = ..., include_prior_dates: bool = ...) -> Any: ...
    def xcom_push(self, *args, **kwargs) -> None: ...
    def get_dagrun(self, *args, **kwargs) -> DagRunPydantic: ...
    def refresh_from_db(self, *args, **kwargs) -> None: ...
    def set_duration(self) -> None: ...
    def clear_next_method_args(self) -> None: ...
    def get_template_context(self, session: Session | None = ..., ignore_param_exceptions: bool = ...) -> Context: ...
    def is_eligible_to_retry(self): ...
    def handle_failure(self, *args, **kwargs) -> None: ...
    def refresh_from_task(self, task: Operator, pool_override: str | None = ...) -> None: ...
    def get_previous_dagrun(self, *args, **kwargs) -> DagRun | None: ...
    def get_previous_execution_date(self, *args, **kwargs) -> pendulum.DateTime | None: ...
    def email_alert(self, exception, task: BaseOperator) -> None: ...
    def get_email_subject_content(self, exception: BaseException, task: BaseOperator | None = ...) -> tuple[str, str, str]: ...
    def get_previous_ti(self, *args, **kwargs) -> TaskInstance | TaskInstancePydantic | None: ...
    def check_and_change_state_before_execution(self, *args, **kwargs) -> bool: ...
    def schedule_downstream_tasks(self, *args, **kwargs): ...
    def command_as_list(self, mark_success: bool = ..., ignore_all_deps: bool = ..., ignore_task_deps: bool = ..., ignore_depends_on_past: bool = ..., wait_for_past_depends_before_skipping: bool = ..., ignore_ti_state: bool = ..., local: bool = ..., pickle_id: int | None = ..., raw: bool = ..., job_id: str | None = ..., pool: str | None = ..., cfg_path: str | None = ...) -> list[str]: ...
    @property
    def stats_tags(self): ...
