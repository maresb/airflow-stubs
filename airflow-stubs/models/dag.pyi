import airflow as airflow
import airflow.exceptions
import airflow.security.permissions as permissions
import airflow.settings as settings
import airflow.utils as utils
import airflow.utils.log.logging_mixin
import airflow.utils.state
import airflow.utils.timezone as timezone
import collections
import collections.abc
import datetime
import functools
import jinja2
import pendulum
import sqlalchemy.ext.associationproxy
import sqlalchemy.orm.decl_api
import sqlalchemy.orm.instrumentation
import sqlalchemy.orm.mapper
import sqlalchemy.sql.schema
import types
from _typeshed import Incomplete
from airflow.api_internal.internal_api_call import internal_api_call as internal_api_call
from airflow.configuration import airflow_conf as airflow_conf
from airflow.datasets.manager import dataset_manager as dataset_manager
from airflow.exceptions import AirflowDagInconsistent as AirflowDagInconsistent, AirflowException as AirflowException, DuplicateTaskIdFound as DuplicateTaskIdFound, FailStopDagInvalidTriggerRule as FailStopDagInvalidTriggerRule, ParamValidationError as ParamValidationError, RemovedInAirflow3Warning as RemovedInAirflow3Warning, TaskDeferred as TaskDeferred, TaskNotFound as TaskNotFound
from airflow.jobs.job import run_job as run_job
from airflow.models.abstractoperator import AbstractOperator as AbstractOperator
from airflow.models.base import StringID as StringID
from airflow.models.baseoperator import BaseOperator as BaseOperator
from airflow.models.dagcode import DagCode as DagCode
from airflow.models.dagpickle import DagPickle as DagPickle
from airflow.models.dagrun import DagRun as DagRun
from airflow.models.param import DagParam as DagParam, ParamsDict as ParamsDict
from airflow.models.taskinstance import TaskInstance as TaskInstance, clear_task_instances as clear_task_instances
from airflow.models.taskinstancekey import TaskInstanceKey as TaskInstanceKey
from airflow.secrets.local_filesystem import LocalFilesystemBackend as LocalFilesystemBackend
from airflow.stats import Stats as Stats
from airflow.timetables.base import DagRunInfo as DagRunInfo, DataInterval as DataInterval, TimeRestriction as TimeRestriction, Timetable as Timetable
from airflow.timetables.interval import CronDataIntervalTimetable as CronDataIntervalTimetable, DeltaDataIntervalTimetable as DeltaDataIntervalTimetable
from airflow.timetables.simple import ContinuousTimetable as ContinuousTimetable, DatasetTriggeredTimetable as DatasetTriggeredTimetable, NullTimetable as NullTimetable, OnceTimetable as OnceTimetable
from airflow.utils.context import Context as Context
from airflow.utils.dag_cycle_tester import check_cycle as check_cycle
from airflow.utils.dates import utils_date_range as utils_date_range
from airflow.utils.decorators import fixup_decorator_warning_stack as fixup_decorator_warning_stack, warnings as warnings
from airflow.utils.helpers import at_most_one as at_most_one, exactly_one as exactly_one, validate_key as validate_key
from airflow.utils.log.logging_mixin import LoggingMixin as LoggingMixin
from airflow.utils.session import provide_session as provide_session
from airflow.utils.sqlalchemy import Interval as Interval, UtcDateTime as UtcDateTime, lock_rows as lock_rows, skip_locked as skip_locked, tuple_in_condition as tuple_in_condition, with_row_locks as with_row_locks
from airflow.utils.state import DagRunState as DagRunState, State as State, TaskInstanceState as TaskInstanceState
from airflow.utils.trigger_rule import TriggerRule as TriggerRule
from airflow.utils.types import ArgNotSet as ArgNotSet, DagRunType as DagRunType, EdgeInfoType as EdgeInfoType, NOTSET as NOTSET
from datetime import timedelta
from typing import Any, Callable, ClassVar, DagStateChangeCallback, Iterable, Iterator, Pattern, SLAMissCallback, ScheduleArg, ScheduleIntervalArg, TaskStateChangeCallback

TYPE_CHECKING: bool
secrets_backend_list: list
RUN_ID_REGEX: str
cron_presets: dict
NEW_SESSION: None
DEFAULT_VIEW_PRESETS: list
ORIENTATION_PRESETS: list
TAG_MAX_LEN: int
DEFAULT_SCHEDULE_INTERVAL: datetime.timedelta

class InconsistentDataInterval(airflow.exceptions.AirflowException):
    _template: ClassVar[str] = ...
    def __init__(self, instance: Any, start_field_name: str, end_field_name: str) -> None: ...
def create_timetable(interval: ScheduleIntervalArg, timezone: Timezone | FixedTimezone) -> Timetable: ...
def get_last_dagrun(dag_id, session, include_externally_triggered: bool = ...): ...
def get_dataset_triggered_next_run_info(dag_ids: list[str]) -> dict[str, dict[str, int | str]]: ...

class DAG(airflow.utils.log.logging_mixin.LoggingMixin):
    _comps: ClassVar[set] = ...
    _DAG__serialized_fields: ClassVar[None] = ...
    parent_dag: ClassVar[None] = ...
    _time_restriction: ClassVar[functools.cached_property] = ...
    task_group_dict: ClassVar[functools.cached_property] = ...
    dag_id: Incomplete
    full_filepath: Incomplete
    concurrency: Incomplete
    max_active_tasks: Incomplete
    access_control: Incomplete
    pickle_id: Incomplete
    tasks: Incomplete
    def __init__(self, dag_id: str, description: str | None = ..., schedule: ScheduleArg = ..., schedule_interval: ScheduleIntervalArg = ..., timetable: Timetable | None = ..., start_date: datetime | None = ..., end_date: datetime | None = ..., full_filepath: str | None = ..., template_searchpath: str | Iterable[str] | None = ..., template_undefined: type[jinja2.StrictUndefined] = ..., user_defined_macros: dict | None = ..., user_defined_filters: dict | None = ..., default_args: dict | None = ..., concurrency: int | None = ..., max_active_tasks: int = ..., max_active_runs: int = ..., dagrun_timeout: timedelta | None = ..., sla_miss_callback: None | SLAMissCallback | list[SLAMissCallback] = ..., default_view: str = ..., orientation: str = ..., catchup: bool = ..., on_success_callback: None | DagStateChangeCallback | list[DagStateChangeCallback] = ..., on_failure_callback: None | DagStateChangeCallback | list[DagStateChangeCallback] = ..., doc_md: str | None = ..., params: collections.abc.MutableMapping | None = ..., access_control: dict | None = ..., is_paused_upon_creation: bool | None = ..., jinja_environment_kwargs: dict | None = ..., render_template_as_native_obj: bool = ..., tags: list[str] | None = ..., owner_links: dict[str, str] | None = ..., auto_register: bool = ..., fail_stop: bool = ...) -> None: ...
    def get_doc_md(self, doc_md: str | None) -> str | None: ...
    def validate(self): ...
    def validate_setup_teardown(self): ...
    def __eq__(self, other) -> bool: ...
    def __ne__(self, other) -> bool: ...
    def __lt__(self, other) -> bool: ...
    def __hash__(self) -> int: ...
    def __enter__(self): ...
    def __exit__(self, _type: type[BaseException] | None, _value: BaseException | None, _tb: types.TracebackType | None): ...
    def date_range(self, start_date: pendulum.DateTime, num: int | None = ..., end_date: datetime | None = ...) -> list[datetime]: ...
    def is_fixed_time_schedule(self): ...
    def following_schedule(self, dttm): ...
    def previous_schedule(self, dttm): ...
    def get_next_data_interval(self, dag_model: DagModel) -> DataInterval | None: ...
    def get_run_data_interval(self, run: DagRun | DagRunPydantic) -> DataInterval: ...
    def infer_automated_data_interval(self, logical_date: datetime) -> DataInterval: ...
    def next_dagrun_info(self, last_automated_dagrun: None | datetime | DataInterval) -> DagRunInfo | None: ...
    def next_dagrun_after_date(self, date_last_automated_dagrun: pendulum.DateTime | None): ...
    def iter_dagrun_infos_between(self, earliest: pendulum.DateTime | None, latest: pendulum.DateTime) -> Iterable[DagRunInfo]: ...
    def get_run_dates(self, start_date, end_date: Incomplete | None = ...) -> list: ...
    def normalize_schedule(self, dttm): ...
    def get_last_dagrun(self, *args, **kwargs): ...
    def has_dag_runs(self, *args, **kwargs) -> bool: ...
    def param(self, name: str, default: Any = ...) -> DagParam: ...
    def get_concurrency_reached(self, *args, **kwargs) -> bool: ...
    def get_is_active(self, *args, **kwargs) -> None: ...
    def get_is_paused(self, *args, **kwargs) -> None: ...
    @staticmethod
    def fetch_callback(*args, **kwargs) -> tuple[list[TaskStateChangeCallback], Context] | None: ...
    def handle_callback(self, *args, **kwargs): ...
    @classmethod
    def execute_callback(cls, callbacks: list[Callable] | None, context: Context | None, dag_id: str): ...
    def get_active_runs(self): ...
    def get_num_active_runs(self, *args, **kwargs): ...
    @staticmethod
    def fetch_dagrun(*args, **kwargs) -> DagRun | DagRunPydantic: ...
    def get_dagrun(self, *args, **kwargs) -> DagRun | DagRunPydantic: ...
    def get_dagruns_between(self, *args, **kwargs): ...
    def get_latest_execution_date(self, *args, **kwargs) -> pendulum.DateTime | None: ...
    def resolve_template_files(self): ...
    def get_template_env(self) -> jinja2.Environment: ...
    def set_dependency(self, upstream_task_id, downstream_task_id): ...
    def get_task_instances_before(self, *args, **kwargs) -> list[TaskInstance]: ...
    def get_task_instances(self, *args, **kwargs) -> list[TaskInstance]: ...
    def set_task_instance_state(self, *args, **kwargs) -> list[TaskInstance]: ...
    def set_task_group_state(self, *args, **kwargs) -> list[TaskInstance]: ...
    def topological_sort(self, include_subdag_tasks: bool = ...): ...
    def set_dag_runs_state(self, *args, **kwargs) -> None: ...
    def clear(self, *args, **kwargs) -> int | Iterable[TaskInstance]: ...
    @classmethod
    def clear_dags(cls, dags, start_date: Incomplete | None = ..., end_date: Incomplete | None = ..., only_failed: bool = ..., only_running: bool = ..., confirm_prompt: bool = ..., include_subdags: bool = ..., include_parentdag: bool = ..., dag_run_state: airflow.utils.state.DagRunState = ..., dry_run: bool = ...): ...
    def __deepcopy__(self, memo): ...
    def sub_dag(self, *args, **kwargs): ...
    def partial_subset(self, task_ids_or_regex: str | Pattern | Iterable[str], include_downstream: bool = ..., include_upstream: bool = ..., include_direct_upstream: bool = ...): ...
    def has_task(self, task_id: str): ...
    def has_task_group(self, task_group_id: str) -> bool: ...
    def get_task(self, task_id: str, include_subdags: bool = ...) -> Operator: ...
    def pickle_info(self): ...
    def pickle(self, *args, **kwargs) -> DagPickle: ...
    def tree_view(self) -> None: ...
    def get_tree_view(self) -> str: ...
    def add_task(self, task: Operator) -> None: ...
    def add_tasks(self, tasks: Iterable[Operator]) -> None: ...
    def run(self, start_date: Incomplete | None = ..., end_date: Incomplete | None = ..., mark_success: bool = ..., local: bool = ..., executor: Incomplete | None = ..., donot_pickle: bool = ..., ignore_task_deps: bool = ..., ignore_first_depends_on_past: bool = ..., pool: Incomplete | None = ..., delay_on_limit_secs: float = ..., verbose: bool = ..., conf: Incomplete | None = ..., rerun_failed_tasks: bool = ..., run_backwards: bool = ..., run_at_least_once: bool = ..., continue_on_failures: bool = ..., disable_retry: bool = ...): ...
    def cli(self): ...
    def test(self, *args, **kwargs) -> DagRun: ...
    def create_dagrun(self, *args, **kwargs): ...
    @classmethod
    def bulk_sync_to_db(cls, *args, **kwargs): ...
    @classmethod
    def bulk_write_to_db(cls, *args, **kwargs): ...
    def sync_to_db(self, *args, **kwargs): ...
    def get_default_view(self): ...
    @staticmethod
    def deactivate_unknown_dags(*args, **kwargs): ...
    @staticmethod
    def deactivate_stale_dags(*args, **kwargs): ...
    @staticmethod
    def get_num_task_instances(*args, **kwargs) -> int: ...
    @classmethod
    def get_serialized_fields(cls): ...
    def get_edge_info(self, upstream_task_id: str, downstream_task_id: str) -> EdgeInfoType: ...
    def set_edge_info(self, upstream_task_id: str, downstream_task_id: str, info: EdgeInfoType): ...
    def validate_schedule_and_params(self): ...
    def iter_invalid_owner_links(self) -> Iterator[tuple[str, str]]: ...
    def __gt__(self, other, NotImplemented: NotImplementedType = ...) -> bool: ...
    def __le__(self, other, NotImplemented: NotImplementedType = ...) -> bool: ...
    def __ge__(self, other, NotImplemented: NotImplementedType = ...) -> bool: ...
    @property
    def is_subdag(self): ...
    @property
    def description(self): ...
    @property
    def default_view(self): ...
    @property
    def task_ids(self): ...
    @property
    def teardowns(self): ...
    @property
    def tasks_upstream_of_teardowns(self): ...
    @property
    def task_group(self): ...
    @property
    def filepath(self): ...
    @property
    def relative_fileloc(self): ...
    @property
    def folder(self): ...
    @property
    def owner(self): ...
    @property
    def allow_future_exec_dates(self): ...
    @property
    def concurrency_reached(self): ...
    @property
    def is_paused(self): ...
    @property
    def normalized_schedule_interval(self): ...
    @property
    def latest_execution_date(self): ...
    @property
    def subdags(self): ...
    @property
    def roots(self): ...
    @property
    def leaves(self): ...
    @property
    def task(self): ...

class DagTag(sqlalchemy.orm.decl_api.Base):
    __tablename__: ClassVar[str] = ...
    _sa_class_manager: ClassVar[sqlalchemy.orm.instrumentation.ClassManager] = ...
    __table__: ClassVar[sqlalchemy.sql.schema.Table] = ...
    __mapper__: ClassVar[sqlalchemy.orm.mapper.Mapper] = ...
    name: Incomplete
    dag_id: Incomplete
    dag: Incomplete
    def __init__(self, **kwargs) -> None: ...

class DagOwnerAttributes(sqlalchemy.orm.decl_api.Base):
    __tablename__: ClassVar[str] = ...
    _sa_class_manager: ClassVar[sqlalchemy.orm.instrumentation.ClassManager] = ...
    __table__: ClassVar[sqlalchemy.sql.schema.Table] = ...
    __mapper__: ClassVar[sqlalchemy.orm.mapper.Mapper] = ...
    dag_id: Incomplete
    owner: Incomplete
    link: Incomplete
    dag: Incomplete
    @classmethod
    def get_all(cls, session) -> dict[str, dict[str, str]]: ...
    def __init__(self, **kwargs) -> None: ...

class DagModel(sqlalchemy.orm.decl_api.Base):
    __tablename__: ClassVar[str] = ...
    is_paused_at_creation: ClassVar[bool] = ...
    __table_args__: ClassVar[tuple] = ...
    NUM_DAGS_PER_DAGRUN_QUERY: ClassVar[int] = ...
    _sa_class_manager: ClassVar[sqlalchemy.orm.instrumentation.ClassManager] = ...
    __table__: ClassVar[sqlalchemy.sql.schema.Table] = ...
    __mapper__: ClassVar[sqlalchemy.orm.mapper.Mapper] = ...
    _AssociationProxy_schedule_dataset_references_140052222293952_inst: ClassVar[sqlalchemy.ext.associationproxy.ObjectAssociationProxyInstance] = ...
    dag_id: Incomplete
    root_dag_id: Incomplete
    is_paused: Incomplete
    is_subdag: Incomplete
    is_active: Incomplete
    last_parsed_time: Incomplete
    last_pickled: Incomplete
    last_expired: Incomplete
    scheduler_lock: Incomplete
    pickle_id: Incomplete
    fileloc: Incomplete
    processor_subdir: Incomplete
    owners: Incomplete
    description: Incomplete
    default_view: Incomplete
    schedule_interval: Incomplete
    timetable_description: Incomplete
    tags: Incomplete
    dag_owner_links: Incomplete
    max_active_tasks: Incomplete
    max_active_runs: Incomplete
    has_task_concurrency_limits: Incomplete
    has_import_errors: Incomplete
    next_dagrun: Incomplete
    next_dagrun_data_interval_start: Incomplete
    next_dagrun_data_interval_end: Incomplete
    next_dagrun_create_after: Incomplete
    parent_dag: Incomplete
    schedule_dataset_references: Incomplete
    schedule_datasets: Incomplete
    task_outlet_dataset_references: Incomplete
    next_dagrun_data_interval: Incomplete
    serialized_dag: Incomplete
    def __init__(self, concurrency: Incomplete | None = ..., **kwargs) -> None: ...
    @staticmethod
    def get_dagmodel(*args, **kwargs) -> DagModel | None: ...
    @classmethod
    def get_current(cls, *args, **kwargs) -> DagModel | DagModelPydantic: ...
    def get_last_dagrun(self, *args, **kwargs): ...
    def get_is_paused(self) -> bool: ...
    def get_is_active(self) -> bool: ...
    @staticmethod
    def get_paused_dag_ids(*args, **kwargs) -> set[str]: ...
    def get_default_view(self) -> str: ...
    def set_is_paused(self, *args, **kwargs) -> None: ...
    @classmethod
    def deactivate_deleted_dags(cls, *args, **kwargs) -> None: ...
    @classmethod
    def dags_needing_dagruns(cls, session: Session) -> tuple[Query, dict[str, tuple[datetime, datetime]]]: ...
    def calculate_dagrun_date_fields(self, dag: DAG, last_automated_dag_run: None | datetime | DataInterval) -> None: ...
    def get_dataset_triggered_next_run_info(self, *args, **kwargs) -> dict[str, int | str] | None: ...
    @property
    def timezone(self): ...
    @property
    def safe_dag_id(self): ...
    @property
    def relative_fileloc(self): ...
def dag(dag_id: str = ..., description: str | None = ..., schedule: ScheduleArg = ..., schedule_interval: ScheduleIntervalArg = ..., timetable: Timetable | None = ..., start_date: datetime | None = ..., end_date: datetime | None = ..., full_filepath: str | None = ..., template_searchpath: str | Iterable[str] | None = ..., template_undefined: type[jinja2.StrictUndefined] = ..., user_defined_macros: dict | None = ..., user_defined_filters: dict | None = ..., default_args: dict | None = ..., concurrency: int | None = ..., max_active_tasks: int = ..., max_active_runs: int = ..., dagrun_timeout: timedelta | None = ..., sla_miss_callback: None | SLAMissCallback | list[SLAMissCallback] = ..., default_view: str = ..., orientation: str = ..., catchup: bool = ..., on_success_callback: None | DagStateChangeCallback | list[DagStateChangeCallback] = ..., on_failure_callback: None | DagStateChangeCallback | list[DagStateChangeCallback] = ..., doc_md: str | None = ..., params: collections.abc.MutableMapping | None = ..., access_control: dict | None = ..., is_paused_upon_creation: bool | None = ..., jinja_environment_kwargs: dict | None = ..., render_template_as_native_obj: bool = ..., tags: list[str] | None = ..., owner_links: dict[str, str] | None = ..., auto_register: bool = ..., fail_stop: bool = ...) -> Callable[[Callable], Callable[..., DAG]]: ...

STATICA_HACK: bool

class DagContext:
    _context_managed_dags: ClassVar[collections.deque] = ...
    autoregistered_dags: ClassVar[set] = ...
    current_autoregister_module_name: ClassVar[None] = ...
    @classmethod
    def push_context_managed_dag(cls, dag: DAG): ...
    @classmethod
    def pop_context_managed_dag(cls) -> DAG | None: ...
    @classmethod
    def get_current_dag(cls) -> DAG | None: ...
