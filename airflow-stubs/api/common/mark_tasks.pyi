import airflow.utils.timezone as timezone
from _typeshed import Incomplete
from airflow.models.dagrun import DagRun as DagRun
from airflow.models.taskinstance import TaskInstance as TaskInstance
from airflow.operators.subdag import SubDagOperator as SubDagOperator
from airflow.utils.helpers import exactly_one as exactly_one
from airflow.utils.session import provide_session as provide_session
from airflow.utils.state import DagRunState as DagRunState, State as State, TaskInstanceState as TaskInstanceState
from airflow.utils.types import DagRunType as DagRunType
from typing import ClassVar, Iterable

TYPE_CHECKING: bool
NEW_SESSION: None

class _DagRunInfo(tuple):
    _fields: ClassVar[tuple] = ...
    _field_defaults: ClassVar[dict] = ...
    _fields_defaults: ClassVar[dict] = ...
    _field_types: ClassVar[dict] = ...
    logical_date: Incomplete
    data_interval: Incomplete
    def __init__(self, _cls, logical_date: datetime, data_interval: tuple[datetime, datetime]) -> None: ...
    def __getnewargs__(self): ...
def set_state(*args, **kwargs) -> list[TaskInstance]: ...
def all_subdag_tasks_query(sub_dag_run_ids: list[str], session: SASession, state: TaskInstanceState, confirmed_dates: Iterable[datetime]): ...
def get_all_dag_task_query(dag: DAG, session: SASession, state: TaskInstanceState, task_ids: list[str | tuple[str, int]], run_ids: Iterable[str]): ...
def verify_dagruns(dag_runs: Iterable[DagRun], commit: bool, state: DagRunState, session: SASession, current_task: Operator): ...
def find_task_relatives(tasks, downstream, upstream): ...
def get_execution_dates(*args, **kwargs) -> list[datetime]: ...
def get_run_ids(*args, **kwargs): ...
def set_dag_run_state_to_success(*args, **kwargs) -> list[TaskInstance]: ...
def set_dag_run_state_to_failed(*args, **kwargs) -> list[TaskInstance]: ...
def set_dag_run_state_to_running(*args, **kwargs) -> list[TaskInstance]: ...
def set_dag_run_state_to_queued(*args, **kwargs) -> list[TaskInstance]: ...
