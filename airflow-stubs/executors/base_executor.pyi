from _typeshed import Incomplete
from airflow.callbacks.base_callback_sink import BaseCallbackSink as BaseCallbackSink
from airflow.callbacks.callback_requests import CallbackRequest as CallbackRequest
from airflow.cli.cli_config import DefaultHelpParser as DefaultHelpParser, GroupCommand as GroupCommand
from airflow.configuration import conf as conf
from airflow.exceptions import RemovedInAirflow3Warning as RemovedInAirflow3Warning
from airflow.executors.executor_loader import ExecutorLoader as ExecutorLoader
from airflow.executors.executor_utils import ExecutorName as ExecutorName
from airflow.models import Log as Log
from airflow.models.taskinstance import TaskInstance as TaskInstance
from airflow.models.taskinstancekey import TaskInstanceKey as TaskInstanceKey
from airflow.stats import Stats as Stats
from airflow.traces import NO_TRACE_ID as NO_TRACE_ID
from airflow.traces.tracer import Trace as Trace, gen_context as gen_context, span as span
from airflow.traces.utils import gen_span_id_from_ti_key as gen_span_id_from_ti_key, gen_trace_id as gen_trace_id
from airflow.utils.log.logging_mixin import LoggingMixin as LoggingMixin
from airflow.utils.state import TaskInstanceState as TaskInstanceState
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Sequence

PARALLELISM: int
CommandType = list[str]
QueuedTaskInstanceType = tuple[CommandType, int, str | None, TaskInstance]
EventBufferValueType = tuple[str | None, Any]
TaskTuple = tuple[TaskInstanceKey, CommandType, str | None, Any | None]
log: Incomplete

@dataclass
class RunningRetryAttemptType:
    MIN_SECONDS = ...
    total_tries: int = field(default=0, init=False)
    tries_after_min: int = field(default=0, init=False)
    first_attempt_time: datetime = field(default_factory=Incomplete, init=False)
    @property
    def elapsed(self): ...
    def can_try_again(self): ...

class BaseExecutor(LoggingMixin):
    supports_ad_hoc_ti_run: bool
    supports_pickling: bool
    supports_sentry: bool
    is_local: bool
    is_single_threaded: bool
    is_production: bool
    change_sensor_mode_to_reschedule: bool
    serve_logs: bool
    job_id: None | int | str
    name: None | ExecutorName
    callback_sink: BaseCallbackSink | None
    parallelism: int
    queued_tasks: dict[TaskInstanceKey, QueuedTaskInstanceType]
    running: set[TaskInstanceKey]
    event_buffer: dict[TaskInstanceKey, EventBufferValueType]
    attempts: dict[TaskInstanceKey, RunningRetryAttemptType]
    def __init__(self, parallelism: int = ...) -> None: ...
    def start(self) -> None: ...
    def log_task_event(self, *, event: str, extra: str, ti_key: TaskInstanceKey): ...
    def queue_command(self, task_instance: TaskInstance, command: CommandType, priority: int = 1, queue: str | None = None): ...
    def queue_task_instance(self, task_instance: TaskInstance, mark_success: bool = False, pickle_id: int | None = None, ignore_all_deps: bool = False, ignore_depends_on_past: bool = False, wait_for_past_depends_before_skipping: bool = False, ignore_task_deps: bool = False, ignore_ti_state: bool = False, pool: str | None = None, cfg_path: str | None = None) -> None: ...
    def has_task(self, task_instance: TaskInstance) -> bool: ...
    def sync(self) -> None: ...
    def heartbeat(self) -> None: ...
    def order_queued_tasks_by_priority(self) -> list[tuple[TaskInstanceKey, QueuedTaskInstanceType]]: ...
    def trigger_tasks(self, open_slots: int) -> None: ...
    def change_state(self, key: TaskInstanceKey, state: TaskInstanceState, info: Incomplete | None = None, remove_running: bool = True) -> None: ...
    def fail(self, key: TaskInstanceKey, info: Incomplete | None = None) -> None: ...
    def success(self, key: TaskInstanceKey, info: Incomplete | None = None) -> None: ...
    def queued(self, key: TaskInstanceKey, info: Incomplete | None = None) -> None: ...
    def running_state(self, key: TaskInstanceKey, info: Incomplete | None = None) -> None: ...
    def get_event_buffer(self, dag_ids: Incomplete | None = None) -> dict[TaskInstanceKey, EventBufferValueType]: ...
    def execute_async(self, key: TaskInstanceKey, command: CommandType, queue: str | None = None, executor_config: Any | None = None) -> None: ...
    def get_task_log(self, ti: TaskInstance, try_number: int) -> tuple[list[str], list[str]]: ...
    def end(self) -> None: ...
    def terminate(self) -> None: ...
    def cleanup_stuck_queued_tasks(self, tis: list[TaskInstance]) -> list[str]: ...
    def revoke_task(self, *, ti: TaskInstance): ...
    def try_adopt_task_instances(self, tis: Sequence[TaskInstance]) -> Sequence[TaskInstance]: ...
    @property
    def slots_available(self): ...
    @property
    def slots_occupied(self): ...
    @staticmethod
    def validate_command(command: list[str]) -> None: ...
    @staticmethod
    def validate_airflow_tasks_run_command(command: list[str]) -> tuple[str | None, str | None]: ...
    def debug_dump(self) -> None: ...
    def send_callback(self, request: CallbackRequest) -> None: ...
    @staticmethod
    def get_cli_commands() -> list[GroupCommand]: ...
