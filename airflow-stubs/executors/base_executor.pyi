import airflow.utils.log.logging_mixin
import dataclasses
from _typeshed import Incomplete
from airflow.cli.cli_config import DefaultHelpParser as DefaultHelpParser
from airflow.configuration import conf as conf
from airflow.exceptions import RemovedInAirflow3Warning as RemovedInAirflow3Warning
from airflow.stats import Stats as Stats
from airflow.utils.log.logging_mixin import LoggingMixin as LoggingMixin
from airflow.utils.state import TaskInstanceState as TaskInstanceState
from typing import Any, ClassVar, Sequence

TYPE_CHECKING: bool
PARALLELISM: int

class RunningRetryAttemptType:
    MIN_SECONDS: ClassVar[int] = ...
    total_tries: ClassVar[int] = ...
    tries_after_min: ClassVar[int] = ...
    __dataclass_params__: ClassVar[dataclasses._DataclassParams] = ...
    __dataclass_fields__: ClassVar[dict] = ...
    def can_try_again(self): ...
    def __init__(self) -> None: ...
    def __eq__(self, other) -> bool: ...
    @property
    def elapsed(self): ...

class BaseExecutor(airflow.utils.log.logging_mixin.LoggingMixin):
    supports_ad_hoc_ti_run: ClassVar[bool] = ...
    supports_pickling: ClassVar[bool] = ...
    supports_sentry: ClassVar[bool] = ...
    is_local: ClassVar[bool] = ...
    is_single_threaded: ClassVar[bool] = ...
    is_production: ClassVar[bool] = ...
    change_sensor_mode_to_reschedule: ClassVar[bool] = ...
    serve_logs: ClassVar[bool] = ...
    job_id: ClassVar[None] = ...
    callback_sink: ClassVar[None] = ...
    def __init__(self, parallelism: int = ...) -> None: ...
    def start(self): ...
    def queue_command(self, task_instance: TaskInstance, command: CommandType, priority: int = ..., queue: str | None = ...): ...
    def queue_task_instance(self, task_instance: TaskInstance, mark_success: bool = ..., pickle_id: int | None = ..., ignore_all_deps: bool = ..., ignore_depends_on_past: bool = ..., wait_for_past_depends_before_skipping: bool = ..., ignore_task_deps: bool = ..., ignore_ti_state: bool = ..., pool: str | None = ..., cfg_path: str | None = ...) -> None: ...
    def has_task(self, task_instance: TaskInstance) -> bool: ...
    def sync(self) -> None: ...
    def heartbeat(self) -> None: ...
    def order_queued_tasks_by_priority(self) -> list[tuple[TaskInstanceKey, QueuedTaskInstanceType]]: ...
    def trigger_tasks(self, open_slots: int) -> None: ...
    def change_state(self, key: TaskInstanceKey, state: TaskInstanceState, info: Incomplete | None = ...) -> None: ...
    def fail(self, key: TaskInstanceKey, info: Incomplete | None = ...) -> None: ...
    def success(self, key: TaskInstanceKey, info: Incomplete | None = ...) -> None: ...
    def get_event_buffer(self, dag_ids: Incomplete | None = ...) -> dict[TaskInstanceKey, EventBufferValueType]: ...
    def execute_async(self, key: TaskInstanceKey, command: CommandType, queue: str | None = ..., executor_config: Any | None = ...) -> None: ...
    def get_task_log(self, ti: TaskInstance, try_number: int) -> tuple[list[str], list[str]]: ...
    def end(self) -> None: ...
    def terminate(self): ...
    def cleanup_stuck_queued_tasks(self, tis: list[TaskInstance]) -> list[str]: ...
    def try_adopt_task_instances(self, tis: Sequence[TaskInstance]) -> Sequence[TaskInstance]: ...
    @staticmethod
    def validate_command(command: list[str]) -> None: ...
    @staticmethod
    def validate_airflow_tasks_run_command(command: list[str]) -> tuple[str | None, str | None]: ...
    def debug_dump(self): ...
    def send_callback(self, request: CallbackRequest) -> None: ...
    @staticmethod
    def get_cli_commands() -> list[GroupCommand]: ...
    @property
    def slots_available(self): ...
